{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rapid-documentation",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinguished-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "increasing-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "model_dir = '/opt/ml/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-building",
   "metadata": {},
   "source": [
    "## 1. Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fourth-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-wrestling",
   "metadata": {},
   "source": [
    "## 2. Training Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "capital-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_root, transform):\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.imag_list = self._load_img_list(data_root)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imag_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Ground Truth\n",
    "        label = self._get_class_idx_from_img_name(img_path)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imag_list)\n",
    "    \n",
    "    def _load_img_list(self, data_root):\n",
    "        img_list = []\n",
    "        image_dir = os.path.join(data_root, 'images')\n",
    "        \n",
    "        for dir in glob.glob(image_dir + '/*'):\n",
    "            img_list.extend(glob.glob(dir+'/*'))\n",
    "\n",
    "        return img_list\n",
    "\n",
    "    def _load_img_ID(self, img_path):\n",
    "        return img_path.split('/')[7].split('_')[0]\n",
    "\n",
    "    def _get_class_idx_from_img_name(self, img_path):\n",
    "        img_name = os.path.basename(img_path)\n",
    "        img_id = self._load_img_ID(img_path)\n",
    "        \n",
    "        img_idx = train_data.loc[train_data['id'] == img_id].index\n",
    "        v = train_data.iloc[img_idx]['age+gender'].values[0]\n",
    "        if 'normal' in img_name:\n",
    "            return 12 + v\n",
    "        elif 'incorrect_mask' in img_name:\n",
    "            return 6 + v\n",
    "        else:\n",
    "            return 0 + v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-calvin",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monetary-economy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "train_data = pd.read_csv(os.path.join(train_dir, 'train_1.csv'))\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "\n",
    "dataset = TrainDataset(train_dir, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = MyModel(num_classes=18).to(device)\n",
    "# model.train(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "falling-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Optimizer\n",
    "from torch.optim import Adam\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prepared-marshall",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "591it [07:52,  1.25it/s]\n",
      "591it [07:49,  1.26it/s]\n",
      "591it [07:48,  1.26it/s]\n",
      "591it [07:56,  1.24it/s]\n",
      "591it [07:56,  1.24it/s]\n",
      "591it [07:53,  1.25it/s]\n",
      "591it [07:55,  1.24it/s]\n",
      "591it [07:56,  1.24it/s]\n",
      "591it [07:55,  1.24it/s]\n",
      "591it [07:56,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter, (img, label) in tqdm(enumerate(loader)):\n",
    "        # optimizer에 저장된 미분값을 0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # GPU 연산을 위해 이미지와 정답 tensor를 GPU로 보내기 (필요한 경우, 변수의 type도 수정해주세요)\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        # 모델에 이미지 forward\n",
    "        pred_logit = model.forward(img)\n",
    "        # print(pred_logit, label)\n",
    "\n",
    "        # loss 값 계산\n",
    "        loss = criterion(pred_logit, label)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy 계산\n",
    "        pred_label = torch.argmax(pred_logit, dim=1)\n",
    "        acc = torch.sum((pred_label == label).float()) / len(img)\n",
    "\n",
    "        train_loss = loss.item()\n",
    "        train_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "contained-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_dir + '/save')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
